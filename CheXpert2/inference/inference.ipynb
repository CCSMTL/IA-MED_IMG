{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import from pypi\n",
    "import tqdm\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local import\n",
    "from CheXpert2.models.CNN import CNN\n",
    "from CheXpert2.Metrics import Metrics\n",
    "from CheXpert2.dataloaders.CXRLoader import CXRLoader\n",
    "from CheXpert2 import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model() :\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        warnings.warn(\"No gpu is available for the computation\")\n",
    "    models = [\n",
    "        CNN(\"convnext_large_384_in22ft1k\", img_size=384, channels=3, num_classes=18, pretrained=False,\n",
    "            pretraining=False),\n",
    "        #    CNN(\"convnext_base\", img_size=384, channels=1, num_classes=14, pretrained=False, pretraining=False),\n",
    "        #    CNN(\"densenet201\", img_size=384, channels=1, num_classes=14, pretrained=False, pretraining=False),\n",
    "        #    CNN(\"densenet201\", img_size=384, channels=1, num_classes=14, pretrained=False, pretraining=False),\n",
    "    ]\n",
    "    # model =  torch.nn.parallel.DistributedDataParallel(model)\n",
    "\n",
    "    # api = wandb.Api()\n",
    "    # run = api.run(f\"ccsmtl2/Chestxray/{args.run_id}\")\n",
    "    # run.file(\"models_weights/convnext_base/DistributedDataParallel.pt\").download(replace=True)\n",
    "    weights = [\n",
    "        \"C:/Users/joeda/PycharmProjects/IA-MED_IMG/IA-med_img/data/model_weights/wobbly_leaf.pt\",\n",
    "        #    \"/data/home/jonathan/IA-MED_IMG/models_weights/convnext_base_2.pt\",\n",
    "        #    \"/data/home/jonathan/IA-MED_IMG/models_weights/densenet201.pt\",\n",
    "        #    \"/data/home/jonathan/IA-MED_IMG/models_weights/densenet201_2.pt\",\n",
    "    ]\n",
    "\n",
    "    for model, weight in zip(models, weights):\n",
    "        state_dict = torch.load(weight, map_location=torch.device(device))\n",
    "\n",
    "        # from collections import OrderedDict\n",
    "        # new_state_dict = OrderedDict()\n",
    "        # for k, v in state_dict.items():\n",
    "        #     name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        #     new_state_dict[name] = v\n",
    "\n",
    "        # model.load_state_dict(new_state_dict)\n",
    "        model.load_state_dict(state_dict)\n",
    "        # model = model.to(device)\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer_loop(model, loader, criterion, device):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model: model to evaluate\n",
    "    :param loader: dataset loader\n",
    "    :param criterion: criterion to evaluate the loss\n",
    "    :param device: device to do the computation on\n",
    "    :return: val_loss for the N epoch, tensor of concatenated labels and predictions\n",
    "    \"\"\"\n",
    "    running_loss = 0\n",
    "    results = [torch.tensor([]), torch.tensor([])]\n",
    "\n",
    "    for inputs, labels,idx in tqdm.tqdm(loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "        inputs, labels = (\n",
    "            inputs.to(device, non_blocking=True),\n",
    "            labels.to(device, non_blocking=True),\n",
    "        )\n",
    "        #inputs,labels = loader.dataset.advanced_transform((inputs, labels))\n",
    "        # forward + backward + optimize\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        running_loss += loss.detach()\n",
    "\n",
    "        if inputs.shape != labels.shape:  # prevent storing images if training unets\n",
    "            results[1] = torch.cat(\n",
    "                (results[1], outputs.detach().cpu()), dim=0\n",
    "            )\n",
    "            results[0] = torch.cat((results[0], labels.cpu()), dim=0)\n",
    "\n",
    "        del (\n",
    "            inputs,\n",
    "            labels,\n",
    "            outputs,\n",
    "            loss,\n",
    "        )  # garbage management sometimes fails with cuda\n",
    "\n",
    "\n",
    "    return running_loss, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "10.128.107.212:27017: timed out, Timeout: 30s, Topology Description: <TopologyDescription id: 639a0e826ed03e595cb9da19, topology_type: Unknown, servers: [<ServerDescription ('10.128.107.212', 27017) server_type: Unknown, rtt: None, error=NetworkTimeout('10.128.107.212:27017: timed out')>]>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mServerSelectionTimeoutError\u001B[0m               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m img_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:/Users/joeda/PycharmProjects/IA-MED_IMG\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     16\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDEBUG\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 17\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mCXRLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mValid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mimg_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m384\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mchannels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mChexPert\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m test_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(\n\u001B[1;32m     20\u001B[0m     test_dataset,\n\u001B[1;32m     21\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m     pin_memory\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     25\u001B[0m )\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# ----------------loading model -------------------------------\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/f/IA-med_img/CheXpert2/dataloaders/CXRLoader.py:118\u001B[0m, in \u001B[0;36mCXRLoader.__init__\u001B[0;34m(self, split, img_dir, img_size, prob, intensity, label_smoothing, channels, use_frontal, datasets, debug)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;66;03m# ------- Caching & Reading -----------------------------------------------------------\u001B[39;00m\n\u001B[1;32m    116\u001B[0m classnames \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# [\"Lung Opacity\", \"Enlarged Cardiomediastinum\"] if pretrain else []\u001B[39;00m\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfiles \u001B[38;5;241m=\u001B[39m \u001B[43mMongoDB\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m10.128.107.212\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m27017\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatasets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_frontal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_frontal\u001B[49m\u001B[43m,\u001B[49m\u001B[43mimg_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimg_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdebug\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdataset(split,\n\u001B[1;32m    119\u001B[0m                                                                                          classnames\u001B[38;5;241m=\u001B[39mclassnames)\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfiles[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfiles[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m    123\u001B[0m paths \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfiles\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExam ID\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPath\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28mlist\u001B[39m)\n",
      "File \u001B[0;32m/mnt/f/IA-med_img/CheXpert2/dataloaders/MongoDB.py:29\u001B[0m, in \u001B[0;36mMongoDB.__init__\u001B[0;34m(self, address, port, collectionnames, use_frontal, img_dir, debug)\u001B[0m\n\u001B[1;32m     26\u001B[0m     collectionnames\u001B[38;5;241m.\u001B[39mremove(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCIUSSS\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m collectionname \u001B[38;5;129;01min\u001B[39;00m collectionnames:\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m collectionname \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdb_public\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_collection_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m collectionnames:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdb_public[name])\n",
      "File \u001B[0;32m~/.virtualenvs/IA-med_img/lib/python3.9/site-packages/pymongo/database.py:959\u001B[0m, in \u001B[0;36mDatabase.list_collection_names\u001B[0;34m(self, session, filter, comment, **kwargs)\u001B[0m\n\u001B[1;32m    956\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mfilter\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mfilter\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mfilter\u001B[39m):\n\u001B[1;32m    957\u001B[0m         kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnameOnly\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_collections\u001B[49m\u001B[43m(\u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m]\n",
      "File \u001B[0;32m~/.virtualenvs/IA-med_img/lib/python3.9/site-packages/pymongo/database.py:911\u001B[0m, in \u001B[0;36mDatabase.list_collections\u001B[0;34m(self, session, filter, comment, **kwargs)\u001B[0m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cmd\u001B[39m(session, server, sock_info, read_preference):\n\u001B[1;32m    907\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_list_collections(\n\u001B[1;32m    908\u001B[0m         sock_info, session, read_preference\u001B[38;5;241m=\u001B[39mread_preference, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    909\u001B[0m     )\n\u001B[0;32m--> 911\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retryable_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_cmd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_pref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/IA-med_img/lib/python3.9/site-packages/pymongo/_csot.py:105\u001B[0m, in \u001B[0;36mapply.<locals>.csot_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m _TimeoutContext(timeout):\n\u001B[1;32m    104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/IA-med_img/lib/python3.9/site-packages/pymongo/mongo_client.py:1441\u001B[0m, in \u001B[0;36mMongoClient._retryable_read\u001B[0;34m(self, func, read_pref, session, address, retryable)\u001B[0m\n\u001B[1;32m   1439\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m last_error\n\u001B[1;32m   1440\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1441\u001B[0m     server \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_select_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43mread_pref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maddress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maddress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1442\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_socket_from_server(read_pref, server, session) \u001B[38;5;28;01mas\u001B[39;00m (sock_info, read_pref):\n\u001B[1;32m   1443\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m retrying \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m retryable:\n\u001B[1;32m   1444\u001B[0m             \u001B[38;5;66;03m# A retry is not possible because this server does\u001B[39;00m\n\u001B[1;32m   1445\u001B[0m             \u001B[38;5;66;03m# not support retryable reads, raise the last error.\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/IA-med_img/lib/python3.9/site-packages/pymongo/mongo_client.py:1257\u001B[0m, in \u001B[0;36mMongoClient._select_server\u001B[0;34m(self, server_selector, session, address)\u001B[0m\n\u001B[1;32m   1255\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m AutoReconnect(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserver \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m no longer available\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m address)\n\u001B[1;32m   1256\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1257\u001B[0m         server \u001B[38;5;241m=\u001B[39m \u001B[43mtopology\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_selector\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1258\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m server\n\u001B[1;32m   1259\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m PyMongoError \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m   1260\u001B[0m     \u001B[38;5;66;03m# Server selection errors in a transaction are transient.\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/IA-med_img/lib/python3.9/site-packages/pymongo/topology.py:272\u001B[0m, in \u001B[0;36mTopology.select_server\u001B[0;34m(self, selector, server_selection_timeout, address)\u001B[0m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect_server\u001B[39m(\u001B[38;5;28mself\u001B[39m, selector, server_selection_timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, address\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;124;03m\"\"\"Like select_servers, but choose a random server if several match.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 272\u001B[0m     server \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_select_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_selection_timeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maddress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _csot\u001B[38;5;241m.\u001B[39mget_timeout():\n\u001B[1;32m    274\u001B[0m         _csot\u001B[38;5;241m.\u001B[39mset_rtt(server\u001B[38;5;241m.\u001B[39mdescription\u001B[38;5;241m.\u001B[39mround_trip_time)\n",
      "File \u001B[0;32m~/.virtualenvs/IA-med_img/lib/python3.9/site-packages/pymongo/topology.py:261\u001B[0m, in \u001B[0;36mTopology._select_server\u001B[0;34m(self, selector, server_selection_timeout, address)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_select_server\u001B[39m(\u001B[38;5;28mself\u001B[39m, selector, server_selection_timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, address\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 261\u001B[0m     servers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect_servers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_selection_timeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maddress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(servers) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m servers[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/.virtualenvs/IA-med_img/lib/python3.9/site-packages/pymongo/topology.py:223\u001B[0m, in \u001B[0;36mTopology.select_servers\u001B[0;34m(self, selector, server_selection_timeout, address)\u001B[0m\n\u001B[1;32m    220\u001B[0m     server_timeout \u001B[38;5;241m=\u001B[39m server_selection_timeout\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m--> 223\u001B[0m     server_descriptions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_select_servers_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_timeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maddress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_server_by_address(sd\u001B[38;5;241m.\u001B[39maddress) \u001B[38;5;28;01mfor\u001B[39;00m sd \u001B[38;5;129;01min\u001B[39;00m server_descriptions]\n",
      "File \u001B[0;32m~/.virtualenvs/IA-med_img/lib/python3.9/site-packages/pymongo/topology.py:238\u001B[0m, in \u001B[0;36mTopology._select_servers_loop\u001B[0;34m(self, selector, timeout, address)\u001B[0m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m server_descriptions:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;66;03m# No suitable servers.\u001B[39;00m\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m now \u001B[38;5;241m>\u001B[39m end_time:\n\u001B[0;32m--> 238\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ServerSelectionTimeoutError(\n\u001B[1;32m    239\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, Timeout: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124ms, Topology Description: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    240\u001B[0m             \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_message(selector), timeout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdescription)\n\u001B[1;32m    241\u001B[0m         )\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_opened()\n\u001B[1;32m    244\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request_check_all()\n",
      "\u001B[0;31mServerSelectionTimeoutError\u001B[0m: 10.128.107.212:27017: timed out, Timeout: 30s, Topology Description: <TopologyDescription id: 639a0e826ed03e595cb9da19, topology_type: Unknown, servers: [<ServerDescription ('10.128.107.212', 27017) server_type: Unknown, rtt: None, error=NetworkTimeout('10.128.107.212:27017: timed out')>]>"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    warnings.warn(\"No gpu is available for the computation\")\n",
    "\n",
    "# ----- parsing arguments -------------------------------------\n",
    "#start = torch.cuda.Event(enable_timing=True)\n",
    "#end = torch.cuda.Event(enable_timing=True)\n",
    "# ------loading test set --------------------------------------\n",
    "#img_dir = os.environ[\"img_dir\"]\n",
    "img_dir = \"C:/Users/joeda/PycharmProjects/IA-MED_IMG\"\n",
    "os.environ[\"DEBUG\"]=\"True\"\n",
    "test_dataset = CXRLoader(\"Valid\",img_dir, img_size=384,channels=3,datasets=[\"ChexPert\"])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")\n",
    "# ----------------loading model -------------------------------\n",
    "\n",
    "model=load_model()\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#start.record()\n",
    "import time\n",
    "start = time.time()\n",
    "running_loss, results = infer_loop(model=model, loader=test_loader, criterion=criterion, device=device)\n",
    "#end.record()\n",
    "end=time.time()\n",
    "#torch.cuda.synchronize()\n",
    "#print(\"time : \", start.elapsed_time(end))\n",
    "print(end-start)\n",
    "#plt.imshow(np.sum(heatmaps[0][0].detach().cpu().numpy(), axis=0))\n",
    "#plt.savefig(\"heatmaps.png\")\n",
    "\n",
    "metric = Metrics(num_classes=18, names=names, threshold=np.zeros((18)) + 0.7)\n",
    "metrics = metric.metrics()\n",
    "metrics_results = {}\n",
    "for key in metrics:\n",
    "    pred = results[1].numpy()\n",
    "    true = results[0].numpy().round(0)\n",
    "    metric_result = metrics[key](true, pred)\n",
    "    metrics_results[key] = metric_result\n",
    "\n",
    "print(metrics_results)\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FOR A SPECIFIC IMAGE\n",
    "\"\"\"\n",
    "#inputs,labels=test_dataset[i]\n",
    "#Manually loading images\n",
    "import cv2 as cv\n",
    "from pytorch_grad_cam import FullGrad\n",
    "from PIL import Image\n",
    "cam=FullGrad(model,target_layers=[])\n",
    "img_size=384\n",
    "img_dir=\"\"\n",
    "path0=\"c:/Users/joeda/PycharmProjects/IA-MED_IMG/data/1808916906062113_view0001.jpg\"\n",
    "path1=\"c:/Users/joeda/PycharmProjects/IA-MED_IMG/data/1808916906062113_view0002.jpg\"\n",
    "assert os.path.exists(path0)\n",
    "image0 = np.array(cv.resize(cv.imread(f\"{img_dir}{path0}\", cv.IMREAD_GRAYSCALE),(img_size,img_size)))\n",
    "image1 = np.array(cv.resize(cv.imread(f\"{img_dir}{path1}\", cv.IMREAD_GRAYSCALE),(img_size,img_size)))\n",
    "inputs = np.concatenate([image0[None,:,:],image1[None,:,:]],axis=0)\n",
    "inputs=inputs[None,:,:,:]\n",
    "# inputs, labels = (\n",
    "#             inputs.to(device, non_blocking=True),\n",
    "#             labels.to(device, non_blocking=True),\n",
    "#         )\n",
    "\n",
    "\n",
    "inputs = torch.from_numpy(inputs).to(device,non_blocking=True)\n",
    "# forward + backward + optimize\n",
    "outputs = model(inputs)\n",
    "img0=inputs[:,0:1,:,:]\n",
    "heatmap0 = cam(img0.float()).squeeze() * -255+255\n",
    "\n",
    "img1=inputs[:,1:2,:,:]\n",
    "heatmap1 = cam(img1.float()).squeeze() * -255+255\n",
    "\n",
    "\n",
    "heatmap0 = np.array(cv.applyColorMap(cv.cvtColor(heatmap0[:, :, None].astype(np.uint8), cv.COLOR_RGB2BGR),\n",
    "                                          cv.COLORMAP_JET))\n",
    "\n",
    "heatmap1 = np.array(cv.applyColorMap(cv.cvtColor(heatmap1[:, :, None].astype(np.uint8), cv.COLOR_RGB2BGR),\n",
    "                                          cv.COLORMAP_JET))\n",
    "\n",
    "Image.fromarray(heatmap0).save(\"c:/Users/joeda/PycharmProjects/IA-MED_IMG/dataheatmap_frontal.jpg\")\n",
    "Image.fromarray(heatmap1).save(\"c:/Users/joeda/PycharmProjects/IA-MED_IMG/dataheatmap_lateral.jpg\")\n",
    "img0=img0.cpu().numpy().astype(np.uint8).squeeze()\n",
    "img1=img1.cpu().numpy().astype(np.uint8).squeeze()\n",
    "img0 = cv.cvtColor(img0,cv.COLOR_GRAY2RGB)\n",
    "img1=cv.cvtColor(img1,cv.COLOR_GRAY2RGB)\n",
    "heatmap0 = cv.addWeighted(heatmap0, 0.5, img0, 0.5, 0)\n",
    "heatmap1 = cv.addWeighted(heatmap1, 0.5, img1, 0.5, 0)\n",
    "plt.imshow(heatmap0.squeeze())\n",
    "plt.show()\n",
    "plt.imshow(heatmap1.squeeze())\n",
    "plt.show()\n",
    "labels=torch.zeros_like(outputs).to(device)\n",
    "#loss = criterion(outputs.squeeze(), labels)\n",
    "outputs = torch.sigmoid(outputs)\n",
    "\n",
    "i+=1\n",
    "plt.imshow(inputs.squeeze().numpy())\n",
    "data=pd.DataFrame([outputs.detach().numpy().squeeze(),labels.numpy().squeeze()],columns=names,index=[\"preds\",\"ground-truth\"])\n",
    "print(data.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#inputs,labels=test_dataset[i]\n",
    "#Manually loading images\n",
    "import cv2 as cv\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam import FullGrad,EigenCAM,GradCAM,HiResCAM,GradCAMPlusPlus,ScoreCAM\n",
    "from PIL import Image\n",
    "\n",
    "cams=[\n",
    "    FullGrad(model,target_layers=[]),\n",
    "    EigenCAM(model,target_layers=[model.backbone.stages[-1]]),\n",
    "    GradCAM(model,target_layers=[model.backbone.stages[-1]]),\n",
    "    HiResCAM(model,target_layers=[model.backbone.stages[-1]]),\n",
    "    ScoreCAM(model,target_layers=[model.backbone.stages[-1]],use_cuda=True),\n",
    "]\n",
    "img_size=512\n",
    "\n",
    "inputs,labels,idx = test_dataset[i]\n",
    "inputs = inputs[None,:,:,:]\n",
    "inputs = inputs.to(device,non_blocking=True)\n",
    "# forward + backward + optimize\n",
    "outputs = model(inputs)\n",
    "img0=inputs[:,0:1,:,:]\n",
    "img1=inputs[:,1:2,:,:]\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "img0_display=img0.cpu().numpy().astype(np.uint8).squeeze()\n",
    "img1_display=img1.cpu().numpy().astype(np.uint8).squeeze()\n",
    "img0_display = cv.cvtColor(img0_display,cv.COLOR_GRAY2RGB)\n",
    "img1_display=cv.cvtColor(img1_display,cv.COLOR_GRAY2RGB)\n",
    "\n",
    "rows=2\n",
    "columns=len(cams)\n",
    "\n",
    "targets = [ClassifierOutputTarget(i) for i,output in enumerate(outputs.squeeze().cpu().tolist()) if output>0.5]\n",
    "\n",
    "for ex,cam in enumerate(cams,start=1) :\n",
    "    heatmap0 = cam(img0.float(),targets=targets).squeeze() * -255+255\n",
    "    heatmap1 = cam(img1.float(),targets=targets).squeeze() * -255+255\n",
    "\n",
    "    fig.add_subplot(rows, columns, ex)\n",
    "    heatmap0 = np.array(cv.applyColorMap(cv.cvtColor(heatmap0[:, :, None].astype(np.uint8), cv.COLOR_RGB2BGR),cv.COLORMAP_JET))\n",
    "    heatmap0 = cv.addWeighted(heatmap0, 0.5, img0_display, 0.5, 0)\n",
    "    plt.imshow(heatmap0.squeeze())\n",
    "\n",
    "    fig.add_subplot(rows, columns, len(cams)+ex)\n",
    "    heatmap1 = np.array(cv.applyColorMap(cv.cvtColor(heatmap1[:, :, None].astype(np.uint8), cv.COLOR_RGB2BGR),cv.COLORMAP_JET))\n",
    "    heatmap1 = cv.addWeighted(heatmap1, 0.5, img1_display, 0.5, 0)\n",
    "    plt.imshow(heatmap1.squeeze())\n",
    "\n",
    "i+=1\n",
    "plt.show()\n",
    "plt.imshow(img0_display)\n",
    "plt.show()\n",
    "plt.imshow(img1_display)\n",
    "plt.show()\n",
    "#Image.fromarray(heatmap0).save(\"c:/Users/joeda/PycharmProjects/IA-MED_IMG/dataheatmap_frontal.jpg\")\n",
    "#Image.fromarray(heatmap1).save(\"c:/Users/joeda/PycharmProjects/IA-MED_IMG/dataheatmap_lateral.jpg\")\n",
    "\n",
    "labels=torch.zeros_like(outputs).to(device)\n",
    "#loss = criterion(outputs.squeeze(), labels)\n",
    "outputs = torch.sigmoid(outputs)\n",
    "\n",
    "data=pd.DataFrame([outputs.cpu().detach().numpy().squeeze(),labels.cpu().numpy().squeeze()],columns=names,index=[\"preds\",\"ground-truth\"])\n",
    "\n",
    "print(data.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
